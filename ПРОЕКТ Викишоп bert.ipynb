{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Проект для «Викишоп»**\n",
    "\n",
    "Интернет-магазин «Викишоп» запускает новый сервис. Теперь пользователи могут редактировать и дополнять описания товаров, как в вики-сообществах. То есть клиенты предлагают свои правки и комментируют изменения других. Магазину нужен инструмент, который будет искать токсичные комментарии и отправлять их на модерацию.\n",
    "\n",
    "Обучите модель классифицировать комментарии на позитивные и негативные. В вашем распоряжении набор данных с разметкой о токсичности правок.\n",
    "\n",
    "Постройте модель со значением метрики качества F1 не меньше 0.75.\n",
    "\n",
    "**Инструкция по выполнению проекта**\n",
    "\n",
    "1. Загрузите и подготовьте данные.\n",
    "2. Обучите разные модели.\n",
    "3. Сделайте выводы.\n",
    "\n",
    "**Описание данных**\n",
    "\n",
    "Данные находятся в файле toxic_comments.csv. Столбец text в нём содержит текст комментария, а toxic — целевой признак."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Подготовка"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: fast_ml in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (3.68)\n",
      "Requirement already satisfied: torch in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (1.10.0)\n",
      "Requirement already satisfied: transformers in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (4.12.5)\n",
      "Requirement already satisfied: seaborn in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (0.11.2)\n",
      "Requirement already satisfied: stop_words in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (2018.7.23)\n",
      "Requirement already satisfied: catboost in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (1.0.3)\n",
      "Requirement already satisfied: typing-extensions in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from torch) (4.0.0)\n",
      "Requirement already satisfied: tqdm>=4.27 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from transformers) (4.42.1)\n",
      "Requirement already satisfied: tokenizers<0.11,>=0.10.1 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from transformers) (0.10.3)\n",
      "Requirement already satisfied: sacremoses in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from transformers) (0.0.46)\n",
      "Requirement already satisfied: pyyaml>=5.1 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from transformers) (5.4.1)\n",
      "Requirement already satisfied: regex!=2019.12.17 in /Users/kate/.local/lib/python3.7/site-packages (from transformers) (2021.11.10)\n",
      "Requirement already satisfied: filelock in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from transformers) (3.4.0)\n",
      "Requirement already satisfied: requests in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from transformers) (2.22.0)\n",
      "Requirement already satisfied: packaging>=20.0 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from transformers) (20.4)\n",
      "Requirement already satisfied: numpy>=1.17 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from transformers) (1.19.1)\n",
      "Requirement already satisfied: huggingface-hub<1.0,>=0.1.0 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from transformers) (0.1.2)\n",
      "Requirement already satisfied: importlib-metadata; python_version < \"3.8\" in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from transformers) (1.7.0)\n",
      "Requirement already satisfied: scipy>=1.0 in /Users/kate/.local/lib/python3.7/site-packages (from seaborn) (1.7.2)\n",
      "Requirement already satisfied: matplotlib>=2.2 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from seaborn) (3.4.2)\n",
      "Requirement already satisfied: pandas>=0.23 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from seaborn) (1.1.1)\n",
      "Requirement already satisfied: graphviz in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from catboost) (0.18.2)\n",
      "Requirement already satisfied: plotly in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from catboost) (5.4.0)\n",
      "Requirement already satisfied: six in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from catboost) (1.14.0)\n",
      "Requirement already satisfied: click in /Users/kate/.local/lib/python3.7/site-packages (from sacremoses->transformers) (8.0.3)\n",
      "Requirement already satisfied: joblib in /Users/kate/.local/lib/python3.7/site-packages (from sacremoses->transformers) (1.1.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from requests->transformers) (2021.5.30)\n",
      "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from requests->transformers) (1.25.8)\n",
      "Requirement already satisfied: idna<2.9,>=2.5 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from requests->transformers) (2.8)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from requests->transformers) (3.0.4)\n",
      "Requirement already satisfied: pyparsing>=2.0.2 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from packaging>=20.0->transformers) (2.4.7)\n",
      "Requirement already satisfied: zipp>=0.5 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from importlib-metadata; python_version < \"3.8\"->transformers) (3.1.0)\n",
      "Requirement already satisfied: cycler>=0.10 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (0.10.0)\n",
      "Requirement already satisfied: pillow>=6.2.0 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (8.2.0)\n",
      "Requirement already satisfied: kiwisolver>=1.0.1 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (1.3.1)\n",
      "Requirement already satisfied: python-dateutil>=2.7 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from matplotlib>=2.2->seaborn) (2.8.1)\n",
      "Requirement already satisfied: pytz>=2017.2 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from pandas>=0.23->seaborn) (2020.1)\n",
      "Requirement already satisfied: tenacity>=6.2.0 in /Users/kate/opt/miniconda3/lib/python3.7/site-packages (from plotly->catboost) (8.0.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install fast_ml torch transformers seaborn stop_words catboost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "from nltk.corpus import stopwords as nltk_stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "import transformers\n",
    "import re \n",
    "from tqdm import notebook\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from catboost import CatBoostClassifier\n",
    "from fast_ml.model_development import train_valid_test_split\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import f1_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Желательно чтобы все импорты были собраны в первой ячейке ноутбука! Если у того, кто будет запускать твой ноутбук будут отсутствовать некоторые библиотеки, то он это увидит сразу, а не в процессе!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  toxic\n",
       "0  Explanation\\nWhy the edits made under my usern...      0\n",
       "1  D'aww! He matches this background colour I'm s...      0\n",
       "2  Hey man, I'm really not trying to edit war. It...      0\n",
       "3  \"\\nMore\\nI can't make any real suggestions on ...      0\n",
       "4  You, sir, are my hero. Any chance you remember...      0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('/Users/kate/Desktop/DS/yandex/Projects/toxic_comments.csv')\n",
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 159571 entries, 0 to 159570\n",
      "Data columns (total 2 columns):\n",
      " #   Column  Non-Null Count   Dtype \n",
      "---  ------  --------------   ----- \n",
      " 0   text    159571 non-null  object\n",
      " 1   toxic   159571 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 2.4+ MB\n"
     ]
    }
   ],
   "source": [
    "data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    143346\n",
       "1     16225\n",
       "Name: toxic, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['toxic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Данные загружены корректно, первичный осмотр проведен. Радует, что баланс классов был изучен.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>new_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why the edits made under my userna...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D aww He matches this background colour I m se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I m really not trying to edit war It s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I can t make any real suggestions on impr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir are my hero Any chance you remember wh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>And for the second time of asking when your vi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>You should be ashamed of yourself That is a ho...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Spitzer Umm theres no actual article for prost...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>And I really don t think you understand I came...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159566  \":::::And for the second time of asking, when ...      0   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159569  And it looks like it was actually you who put ...      0   \n",
       "159570  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                                 new_text  \n",
       "0       Explanation Why the edits made under my userna...  \n",
       "1       D aww He matches this background colour I m se...  \n",
       "2       Hey man I m really not trying to edit war It s...  \n",
       "3       More I can t make any real suggestions on impr...  \n",
       "4       You sir are my hero Any chance you remember wh...  \n",
       "...                                                   ...  \n",
       "159566  And for the second time of asking when your vi...  \n",
       "159567  You should be ashamed of yourself That is a ho...  \n",
       "159568  Spitzer Umm theres no actual article for prost...  \n",
       "159569  And it looks like it was actually you who put ...  \n",
       "159570  And I really don t think you understand I came...  \n",
       "\n",
       "[159571 rows x 3 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def clear_text(text):\n",
    "    new_text = []\n",
    "    for i in text:\n",
    "        new_text.append(\" \".join(re.sub(r'[^a-zA-Z]', ' ', i).split()))\n",
    "    return new_text\n",
    "\n",
    "data['new_text'] = clear_text(data['text'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Очистка была сделана верно.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/kate/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>new_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Explanation, Why, edits, made, username, Hard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>[D, aww, He, matches, background, colour, I, s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Hey, man, I, really, trying, edit, war, It, g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[More, I, make, real, suggestions, improvement...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>[You, sir, hero, Any, chance, remember, page]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[And, second, time, asking, view, completely, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[You, ashamed, That, horrible, thing, put, tal...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[Spitzer, Umm, theres, actual, article, prosti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>[And, looks, like, actually, put, speedy, firs...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>[And, I, really, think, understand, I, came, i...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159566  \":::::And for the second time of asking, when ...      0   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159569  And it looks like it was actually you who put ...      0   \n",
       "159570  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                                 new_text  \n",
       "0       [Explanation, Why, edits, made, username, Hard...  \n",
       "1       [D, aww, He, matches, background, colour, I, s...  \n",
       "2       [Hey, man, I, really, trying, edit, war, It, g...  \n",
       "3       [More, I, make, real, suggestions, improvement...  \n",
       "4           [You, sir, hero, Any, chance, remember, page]  \n",
       "...                                                   ...  \n",
       "159566  [And, second, time, asking, view, completely, ...  \n",
       "159567  [You, ashamed, That, horrible, thing, put, tal...  \n",
       "159568  [Spitzer, Umm, theres, actual, article, prosti...  \n",
       "159569  [And, looks, like, actually, put, speedy, firs...  \n",
       "159570  [And, I, really, think, understand, I, came, i...  \n",
       "\n",
       "[159571 rows x 3 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(nltk_stopwords.words('english'))\n",
    "\n",
    "def stopwords(text):\n",
    "    new_text = []\n",
    "    for word_list in text:\n",
    "        line = []\n",
    "        line = [x for x in word_list.split() if not x in stop_words]\n",
    "        new_text.append(line)\n",
    "    return new_text\n",
    "\n",
    "data['new_text'] = stopwords(data['new_text'])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to /Users/kate/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>new_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Explanation\\nWhy the edits made under my usern...</td>\n",
       "      <td>0</td>\n",
       "      <td>Explanation Why edits made username Hardcore M...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>D aww He match background colour I seemingly s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>Hey man I really trying edit war It guy consta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>More I make real suggestion improvement I wond...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>You sir hero Any chance remember page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159566</th>\n",
       "      <td>\":::::And for the second time of asking, when ...</td>\n",
       "      <td>0</td>\n",
       "      <td>And second time asking view completely contrad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159567</th>\n",
       "      <td>You should be ashamed of yourself \\n\\nThat is ...</td>\n",
       "      <td>0</td>\n",
       "      <td>You ashamed That horrible thing put talk page</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159568</th>\n",
       "      <td>Spitzer \\n\\nUmm, theres no actual article for ...</td>\n",
       "      <td>0</td>\n",
       "      <td>Spitzer Umm there actual article prostitution ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159569</th>\n",
       "      <td>And it looks like it was actually you who put ...</td>\n",
       "      <td>0</td>\n",
       "      <td>And look like actually put speedy first versio...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159570</th>\n",
       "      <td>\"\\nAnd ... I really don't think you understand...</td>\n",
       "      <td>0</td>\n",
       "      <td>And I really think understand I came idea bad ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>159571 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                     text  toxic  \\\n",
       "0       Explanation\\nWhy the edits made under my usern...      0   \n",
       "1       D'aww! He matches this background colour I'm s...      0   \n",
       "2       Hey man, I'm really not trying to edit war. It...      0   \n",
       "3       \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4       You, sir, are my hero. Any chance you remember...      0   \n",
       "...                                                   ...    ...   \n",
       "159566  \":::::And for the second time of asking, when ...      0   \n",
       "159567  You should be ashamed of yourself \\n\\nThat is ...      0   \n",
       "159568  Spitzer \\n\\nUmm, theres no actual article for ...      0   \n",
       "159569  And it looks like it was actually you who put ...      0   \n",
       "159570  \"\\nAnd ... I really don't think you understand...      0   \n",
       "\n",
       "                                                 new_text  \n",
       "0       Explanation Why edits made username Hardcore M...  \n",
       "1       D aww He match background colour I seemingly s...  \n",
       "2       Hey man I really trying edit war It guy consta...  \n",
       "3       More I make real suggestion improvement I wond...  \n",
       "4                   You sir hero Any chance remember page  \n",
       "...                                                   ...  \n",
       "159566  And second time asking view completely contrad...  \n",
       "159567      You ashamed That horrible thing put talk page  \n",
       "159568  Spitzer Umm there actual article prostitution ...  \n",
       "159569  And look like actually put speedy first versio...  \n",
       "159570  And I really think understand I came idea bad ...  \n",
       "\n",
       "[159571 rows x 3 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('wordnet')\n",
    "stemmer = nltk.WordNetLemmatizer()\n",
    "\n",
    "def lemmatize(text):\n",
    "    lemm_text = []\n",
    "    for word_list in text:\n",
    "        lemm_text.append(\" \".join(stemmer.lemmatize(word) for word in word_list))\n",
    "    return lemm_text\n",
    "\n",
    "data['new_text'] = lemmatize(data['new_text'])\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ВЫВОД 1**\n",
    "\n",
    "- данные импортированы\n",
    "- в тексте оставлены только слова, убраны стопслова, текст лемматизирован"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Отлично, что лемматизатор был применен именно к словам.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Обучение "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Слова будут преобразовываться в векторы двумя способами:**\n",
    "\n",
    "1. BERT\n",
    "2. TfidfVectorizer\n",
    "\n",
    "## BERT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Token indices sequence length is longer than the specified maximum sequence length for this model (678 > 512). Running this sequence through the model will result in indexing errors\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[  101,  7526,  2339,  ...,     0,     0,     0],\n",
       "        [  101,  1040, 22091,  ...,     0,     0,     0],\n",
       "        [  101,  4931,  2158,  ...,     0,     0,     0],\n",
       "        ...,\n",
       "        [  101, 13183,  6290,  ...,     0,     0,     0],\n",
       "        [  101,  1998,  2298,  ...,     0,     0,     0],\n",
       "        [  101,  1998,  1045,  ...,     0,     0,     0]]), 'token_type_ids': tensor([[0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0],\n",
       "        [0, 0, 0,  ..., 0, 0, 0]]), 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        ...,\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0],\n",
       "        [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer = transformers.BertTokenizer.from_pretrained('bert-base-uncased')\n",
    "\n",
    "# tokenized = data['new_text'].apply(\n",
    "#     lambda x: tokenizer.encode(x, add_special_tokens=True, padding = \"max_length\", \n",
    "#                               truncation = True, return_attention_mask = True, return_tensors = \"pt\"))\n",
    "\n",
    "# tokenized\n",
    "\n",
    "# преобразование слов в токены\n",
    "encoded_text = tokenizer(list(data['new_text']), add_special_tokens=True, padding = True, \n",
    "                         return_attention_mask = True, return_tensors = \"pt\")\n",
    "encoded_text\n",
    "# for i in tokenized.values:\n",
    "#     if len(i) > max_len:\n",
    "#         max_len = len(i)\n",
    "\n",
    "# padded = np.array([i + [0]*(max_len - len(i)) for i in tokenized.values])\n",
    "\n",
    "# attention_mask = np.where(padded != 0, 1, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['input_ids', 'token_type_ids', 'attention_mask'])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_text.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([159571, 512])\n",
      "torch.Size([159571, 512])\n",
      "torch.Size([159571, 512])\n"
     ]
    }
   ],
   "source": [
    "encoded_text['input_ids'] = ((encoded_text['input_ids'].T)[:512]).T\n",
    "print(encoded_text['input_ids'].shape)\n",
    "\n",
    "encoded_text['token_type_ids'] = ((encoded_text['token_type_ids'].T)[:512]).T\n",
    "print(encoded_text['token_type_ids'].shape)\n",
    "\n",
    "encoded_text['attention_mask'] = ((encoded_text['attention_mask'].T)[:512]).T\n",
    "print(encoded_text['attention_mask'].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# взято только первые 500 строк \n",
    "encoded_text_bert = encoded_text.copy()\n",
    "encoded_text_bert['input_ids'] = encoded_text_bert['input_ids'][:500]\n",
    "encoded_text_bert['token_type_ids'] = encoded_text_bert['token_type_ids'][:500]\n",
    "encoded_text_bert['attention_mask'] = encoded_text_bert['attention_mask'][:500]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-base-uncased were not used when initializing BertModel: ['cls.predictions.transform.dense.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.predictions.transform.dense.weight', 'cls.seq_relationship.bias', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.bias', 'cls.seq_relationship.weight', 'cls.predictions.decoder.weight']\n",
      "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e7cd60f3e7dd4d05b8fb60031bb97719",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=500.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# создание эмбэддингов\n",
    "model = transformers.BertModel.from_pretrained('bert-base-uncased')\n",
    "batch_size = 1\n",
    "embeddings = []\n",
    "with torch.no_grad():\n",
    "    for i in notebook.tqdm(range(0, len(encoded_text_bert['input_ids']), batch_size)):\n",
    "        bert_embeddings = model(\n",
    "            input_ids = encoded_text_bert['input_ids'][i: i + batch_size], \n",
    "            attention_mask = encoded_text_bert['attention_mask'][i: i + batch_size]\n",
    "  \n",
    "        )\n",
    "        embeddings.append(bert_embeddings[0][:,0,:].numpy())                \n",
    "\n",
    "\n",
    "# for i in notebook.tqdm(range(padded.shape[0] // batch_size)):\n",
    "#         batch = torch.LongTensor(padded[batch_size*i:batch_size*(i+1)]) \n",
    "#         attention_mask_batch = torch.LongTensor(attention_mask[batch_size*i:batch_size*(i+1)])\n",
    "        \n",
    "#         with torch.no_grad():\n",
    "#             batch_embeddings = model(batch, attention_mask=attention_mask_batch)\n",
    "        \n",
    "#         embeddings.append(batch_embeddings[0][:,0,:].numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "features = np.vstack(embeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>758</th>\n",
       "      <th>759</th>\n",
       "      <th>760</th>\n",
       "      <th>761</th>\n",
       "      <th>762</th>\n",
       "      <th>763</th>\n",
       "      <th>764</th>\n",
       "      <th>765</th>\n",
       "      <th>766</th>\n",
       "      <th>767</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.003943</td>\n",
       "      <td>-0.038551</td>\n",
       "      <td>-0.191658</td>\n",
       "      <td>-0.416463</td>\n",
       "      <td>-0.100273</td>\n",
       "      <td>-0.181285</td>\n",
       "      <td>0.586726</td>\n",
       "      <td>0.504233</td>\n",
       "      <td>-0.136987</td>\n",
       "      <td>-0.255546</td>\n",
       "      <td>...</td>\n",
       "      <td>0.123200</td>\n",
       "      <td>-0.140592</td>\n",
       "      <td>0.253080</td>\n",
       "      <td>-0.075918</td>\n",
       "      <td>0.367628</td>\n",
       "      <td>-0.005794</td>\n",
       "      <td>-0.419067</td>\n",
       "      <td>-0.402295</td>\n",
       "      <td>-0.012533</td>\n",
       "      <td>0.486601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.370478</td>\n",
       "      <td>-0.229204</td>\n",
       "      <td>0.351519</td>\n",
       "      <td>-0.246613</td>\n",
       "      <td>-0.471595</td>\n",
       "      <td>-0.353639</td>\n",
       "      <td>0.769191</td>\n",
       "      <td>0.443525</td>\n",
       "      <td>0.105449</td>\n",
       "      <td>-0.058893</td>\n",
       "      <td>...</td>\n",
       "      <td>0.188431</td>\n",
       "      <td>-0.236262</td>\n",
       "      <td>0.221057</td>\n",
       "      <td>0.097152</td>\n",
       "      <td>0.034832</td>\n",
       "      <td>-0.159341</td>\n",
       "      <td>0.003167</td>\n",
       "      <td>-0.648572</td>\n",
       "      <td>0.359582</td>\n",
       "      <td>0.716788</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.124796</td>\n",
       "      <td>0.196310</td>\n",
       "      <td>0.029785</td>\n",
       "      <td>-0.136838</td>\n",
       "      <td>-0.732282</td>\n",
       "      <td>-0.408913</td>\n",
       "      <td>0.496076</td>\n",
       "      <td>0.881864</td>\n",
       "      <td>-0.173776</td>\n",
       "      <td>-0.327263</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.305325</td>\n",
       "      <td>-0.191583</td>\n",
       "      <td>0.075978</td>\n",
       "      <td>0.080356</td>\n",
       "      <td>0.393167</td>\n",
       "      <td>0.148950</td>\n",
       "      <td>-0.178105</td>\n",
       "      <td>-0.359515</td>\n",
       "      <td>0.618104</td>\n",
       "      <td>0.506780</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.007574</td>\n",
       "      <td>0.238556</td>\n",
       "      <td>0.315752</td>\n",
       "      <td>-0.162564</td>\n",
       "      <td>-0.227713</td>\n",
       "      <td>-0.431189</td>\n",
       "      <td>0.172111</td>\n",
       "      <td>0.384288</td>\n",
       "      <td>-0.128905</td>\n",
       "      <td>-0.052831</td>\n",
       "      <td>...</td>\n",
       "      <td>0.071006</td>\n",
       "      <td>-0.351603</td>\n",
       "      <td>-0.056626</td>\n",
       "      <td>0.399258</td>\n",
       "      <td>0.306327</td>\n",
       "      <td>-0.137928</td>\n",
       "      <td>-0.485954</td>\n",
       "      <td>-0.476714</td>\n",
       "      <td>0.260979</td>\n",
       "      <td>0.525012</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.026004</td>\n",
       "      <td>0.145654</td>\n",
       "      <td>0.151565</td>\n",
       "      <td>-0.167552</td>\n",
       "      <td>-0.324778</td>\n",
       "      <td>-0.263809</td>\n",
       "      <td>0.298572</td>\n",
       "      <td>0.608470</td>\n",
       "      <td>0.088514</td>\n",
       "      <td>0.055187</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.025698</td>\n",
       "      <td>-0.367768</td>\n",
       "      <td>0.093500</td>\n",
       "      <td>0.191290</td>\n",
       "      <td>0.029543</td>\n",
       "      <td>-0.097696</td>\n",
       "      <td>-0.211805</td>\n",
       "      <td>-0.541219</td>\n",
       "      <td>-0.000663</td>\n",
       "      <td>0.404261</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>-0.124434</td>\n",
       "      <td>-0.045278</td>\n",
       "      <td>-0.144127</td>\n",
       "      <td>0.130008</td>\n",
       "      <td>-0.176664</td>\n",
       "      <td>-0.470352</td>\n",
       "      <td>0.490547</td>\n",
       "      <td>0.630391</td>\n",
       "      <td>-0.341693</td>\n",
       "      <td>-0.024476</td>\n",
       "      <td>...</td>\n",
       "      <td>0.109039</td>\n",
       "      <td>0.078683</td>\n",
       "      <td>0.111596</td>\n",
       "      <td>-0.286132</td>\n",
       "      <td>-0.004543</td>\n",
       "      <td>-0.390831</td>\n",
       "      <td>-0.041959</td>\n",
       "      <td>-0.011874</td>\n",
       "      <td>0.557075</td>\n",
       "      <td>0.407108</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0.045821</td>\n",
       "      <td>0.045132</td>\n",
       "      <td>0.495879</td>\n",
       "      <td>-0.199855</td>\n",
       "      <td>-0.107832</td>\n",
       "      <td>-0.286765</td>\n",
       "      <td>0.486568</td>\n",
       "      <td>0.418575</td>\n",
       "      <td>-0.118376</td>\n",
       "      <td>-0.358943</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.278910</td>\n",
       "      <td>-0.332389</td>\n",
       "      <td>-0.256643</td>\n",
       "      <td>0.289449</td>\n",
       "      <td>0.269922</td>\n",
       "      <td>-0.180460</td>\n",
       "      <td>-0.362857</td>\n",
       "      <td>-0.243672</td>\n",
       "      <td>0.172332</td>\n",
       "      <td>0.068301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>-0.467393</td>\n",
       "      <td>0.221900</td>\n",
       "      <td>-0.451334</td>\n",
       "      <td>0.196944</td>\n",
       "      <td>-0.770069</td>\n",
       "      <td>0.592165</td>\n",
       "      <td>0.480514</td>\n",
       "      <td>0.561038</td>\n",
       "      <td>-0.697607</td>\n",
       "      <td>0.151172</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.069998</td>\n",
       "      <td>0.344805</td>\n",
       "      <td>0.196829</td>\n",
       "      <td>0.232389</td>\n",
       "      <td>0.231368</td>\n",
       "      <td>-0.437250</td>\n",
       "      <td>-0.167758</td>\n",
       "      <td>-0.081547</td>\n",
       "      <td>0.442517</td>\n",
       "      <td>0.026120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>-0.280228</td>\n",
       "      <td>0.055083</td>\n",
       "      <td>-0.051474</td>\n",
       "      <td>-0.056231</td>\n",
       "      <td>0.045012</td>\n",
       "      <td>-0.264153</td>\n",
       "      <td>0.300203</td>\n",
       "      <td>0.549051</td>\n",
       "      <td>-0.346395</td>\n",
       "      <td>-0.061949</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.122788</td>\n",
       "      <td>0.029805</td>\n",
       "      <td>-0.119288</td>\n",
       "      <td>-0.137450</td>\n",
       "      <td>0.098796</td>\n",
       "      <td>-0.036382</td>\n",
       "      <td>-0.488359</td>\n",
       "      <td>-0.371308</td>\n",
       "      <td>0.241362</td>\n",
       "      <td>0.345105</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>-0.075241</td>\n",
       "      <td>0.135092</td>\n",
       "      <td>0.181557</td>\n",
       "      <td>-0.166875</td>\n",
       "      <td>-0.332698</td>\n",
       "      <td>-0.577949</td>\n",
       "      <td>0.332702</td>\n",
       "      <td>0.605940</td>\n",
       "      <td>-0.021771</td>\n",
       "      <td>-0.029469</td>\n",
       "      <td>...</td>\n",
       "      <td>0.019859</td>\n",
       "      <td>-0.357158</td>\n",
       "      <td>0.066211</td>\n",
       "      <td>0.056342</td>\n",
       "      <td>0.146611</td>\n",
       "      <td>0.047351</td>\n",
       "      <td>-0.241332</td>\n",
       "      <td>-0.236406</td>\n",
       "      <td>0.291557</td>\n",
       "      <td>0.182640</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 768 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "          0         1         2         3         4         5         6    \\\n",
       "0    0.003943 -0.038551 -0.191658 -0.416463 -0.100273 -0.181285  0.586726   \n",
       "1   -0.370478 -0.229204  0.351519 -0.246613 -0.471595 -0.353639  0.769191   \n",
       "2    0.124796  0.196310  0.029785 -0.136838 -0.732282 -0.408913  0.496076   \n",
       "3    0.007574  0.238556  0.315752 -0.162564 -0.227713 -0.431189  0.172111   \n",
       "4   -0.026004  0.145654  0.151565 -0.167552 -0.324778 -0.263809  0.298572   \n",
       "..        ...       ...       ...       ...       ...       ...       ...   \n",
       "495 -0.124434 -0.045278 -0.144127  0.130008 -0.176664 -0.470352  0.490547   \n",
       "496  0.045821  0.045132  0.495879 -0.199855 -0.107832 -0.286765  0.486568   \n",
       "497 -0.467393  0.221900 -0.451334  0.196944 -0.770069  0.592165  0.480514   \n",
       "498 -0.280228  0.055083 -0.051474 -0.056231  0.045012 -0.264153  0.300203   \n",
       "499 -0.075241  0.135092  0.181557 -0.166875 -0.332698 -0.577949  0.332702   \n",
       "\n",
       "          7         8         9    ...       758       759       760  \\\n",
       "0    0.504233 -0.136987 -0.255546  ...  0.123200 -0.140592  0.253080   \n",
       "1    0.443525  0.105449 -0.058893  ...  0.188431 -0.236262  0.221057   \n",
       "2    0.881864 -0.173776 -0.327263  ... -0.305325 -0.191583  0.075978   \n",
       "3    0.384288 -0.128905 -0.052831  ...  0.071006 -0.351603 -0.056626   \n",
       "4    0.608470  0.088514  0.055187  ... -0.025698 -0.367768  0.093500   \n",
       "..        ...       ...       ...  ...       ...       ...       ...   \n",
       "495  0.630391 -0.341693 -0.024476  ...  0.109039  0.078683  0.111596   \n",
       "496  0.418575 -0.118376 -0.358943  ... -0.278910 -0.332389 -0.256643   \n",
       "497  0.561038 -0.697607  0.151172  ... -0.069998  0.344805  0.196829   \n",
       "498  0.549051 -0.346395 -0.061949  ... -0.122788  0.029805 -0.119288   \n",
       "499  0.605940 -0.021771 -0.029469  ...  0.019859 -0.357158  0.066211   \n",
       "\n",
       "          761       762       763       764       765       766       767  \n",
       "0   -0.075918  0.367628 -0.005794 -0.419067 -0.402295 -0.012533  0.486601  \n",
       "1    0.097152  0.034832 -0.159341  0.003167 -0.648572  0.359582  0.716788  \n",
       "2    0.080356  0.393167  0.148950 -0.178105 -0.359515  0.618104  0.506780  \n",
       "3    0.399258  0.306327 -0.137928 -0.485954 -0.476714  0.260979  0.525012  \n",
       "4    0.191290  0.029543 -0.097696 -0.211805 -0.541219 -0.000663  0.404261  \n",
       "..        ...       ...       ...       ...       ...       ...       ...  \n",
       "495 -0.286132 -0.004543 -0.390831 -0.041959 -0.011874  0.557075  0.407108  \n",
       "496  0.289449  0.269922 -0.180460 -0.362857 -0.243672  0.172332  0.068301  \n",
       "497  0.232389  0.231368 -0.437250 -0.167758 -0.081547  0.442517  0.026120  \n",
       "498 -0.137450  0.098796 -0.036382 -0.488359 -0.371308  0.241362  0.345105  \n",
       "499  0.056342  0.146611  0.047351 -0.241332 -0.236406  0.291557  0.182640  \n",
       "\n",
       "[500 rows x 768 columns]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>toxic</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>495</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>496</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>497</th>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>498</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>499</th>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>500 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     toxic\n",
       "0        0\n",
       "1        0\n",
       "2        0\n",
       "3        0\n",
       "4        0\n",
       "..     ...\n",
       "495      0\n",
       "496      0\n",
       "497      1\n",
       "498      0\n",
       "499      0\n",
       "\n",
       "[500 rows x 1 columns]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target = data['toxic'][:500]\n",
    "pd.DataFrame(target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_rem, y_train, y_rem = train_test_split(features,target, train_size=0.6)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "def model(model, model_name):\n",
    "    model = model\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_valid)\n",
    "    result.append(pd.Series({'Estimator' : model_name,\n",
    "                             'F1 score:' : f1_score(y_valid, pred)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(LogisticRegression(random_state=12345, class_weight='balanced'), 'LogisticRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(DecisionTreeClassifier(random_state = 12345, max_depth=10), 'DecisionTreeClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(RandomForestClassifier(random_state=12345, class_weight='balanced', n_estimators=100, max_depth=10), \n",
    "     'RandomForestClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:\tlearn: 0.2555684\ttotal: 1.98s\tremaining: 7.91s\n",
      "1:\tlearn: 0.1190436\ttotal: 3.68s\tremaining: 5.52s\n",
      "2:\tlearn: 0.0625236\ttotal: 5.36s\tremaining: 3.57s\n",
      "3:\tlearn: 0.0424755\ttotal: 7.15s\tremaining: 1.79s\n",
      "4:\tlearn: 0.0315904\ttotal: 9.21s\tremaining: 0us\n"
     ]
    }
   ],
   "source": [
    "model(CatBoostClassifier(iterations=5, learning_rate=1, loss_function='Logloss', depth=10), 'CatBoostClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score:</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.444444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CatBoostClassifier</th>\n",
       "      <td>0.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       F1 score:\n",
       "Estimator                       \n",
       "LogisticRegression      0.714286\n",
       "DecisionTreeClassifier      0.25\n",
       "RandomForestClassifier  0.444444\n",
       "CatBoostClassifier           0.2"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results = pd.concat(result, axis=1).T.set_index('Estimator')\n",
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.6\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "print('F1 score:', f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ВЫВОД 2.1**\n",
    "\n",
    "- использована модель BERT\n",
    "- наилучший результат показала LogisticRegression, на валидационной выборке F1 = 0.7, на тестовой 0.6; скорее всего результат улучшился бы при подборе определенных параметров методом gridsearchcv"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Молодец, что освоил векторизацию с помощью БЕРТа!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TfidfVectorizer "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer \n",
    "#corpus = data['new_text'].values.astype('U')\n",
    "# tf_idf = TfidfVectorizer().fit_transform(corpus)\n",
    "# tf_idf.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data['new_text']\n",
    "y = data['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_rem, y_train, y_rem = train_test_split(X, y, train_size=0.6)\n",
    "X_valid, X_test, y_valid, y_test = train_test_split(X_rem,y_rem, test_size=0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-danger\">\n",
    "<b>Ошибка:</b> Векторизатор можно обучать только после разбиения выборки на части. При этом он должен быть обучен только на тренировочной части данных.\n",
    "</div>\n",
    "\n",
    "<div class=\"alert alert-block alert-warning\">\n",
    "<b>Изменения:</b> Векторизатор теперь обучен после разбиения \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = X_train.values.astype('U')\n",
    "corpus2 = X_valid.values.astype('U')\n",
    "corpus3 = X_test.values.astype('U')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "X_train = vectorizer.fit_transform(corpus)\n",
    "_vectorizer = vectorizer\n",
    "X_valid = _vectorizer.transform(corpus2)\n",
    "X_test = _vectorizer.transform(corpus3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = []\n",
    "def model(model, model_name):\n",
    "    model = model\n",
    "    model.fit(X_train, y_train)\n",
    "    pred = model.predict(X_valid)\n",
    "    result.append(pd.Series({'Estimator' : model_name,\n",
    "        'F1 score:' : f1_score(y_valid, pred)}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(LogisticRegression(random_state=12345, class_weight='balanced'), 'LogisticRegression')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(DecisionTreeClassifier(random_state = 12345, max_depth=10), 'DecisionTreeClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "model(RandomForestClassifier(random_state=12345, n_estimators=100, max_depth=10, class_weight='balanced'), \n",
    "      'RandomForestClassifier')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>F1 score:</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Estimator</th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LogisticRegression</th>\n",
       "      <td>0.750343</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>DecisionTreeClassifier</th>\n",
       "      <td>0.582074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>RandomForestClassifier</th>\n",
       "      <td>0.368487</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       F1 score:\n",
       "Estimator                       \n",
       "LogisticRegression      0.750343\n",
       "DecisionTreeClassifier  0.582074\n",
       "RandomForestClassifier  0.368487"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "best_results = pd.concat(result, axis=1).T.set_index('Estimator')\n",
    "best_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "F1 score: 0.7496288298015927\n"
     ]
    }
   ],
   "source": [
    "model = LogisticRegression(random_state=12345, class_weight='balanced')\n",
    "model.fit(X_train, y_train)\n",
    "pred = model.predict(X_test)\n",
    "print('F1 score:', f1_score(y_test, pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Совет: </b> Можно было подобрать параметры. Напомню, что внутри кросс-валидации происходит разбиение выборки на треин и валидацию. Однако, в таком случае векторизатор обучен на всей выборке, а это не совсем корректно. Для избежания такого эффекта можно использовать <a href=\"https://scikit-learn.org/stable/modules/generated/sklearn.pipeline.Pipeline.html\">пайплайн</a>. <a href=\"https://medium.com/analytics-vidhya/ml-pipelines-using-scikit-learn-and-gridsearchcv-fe605a7f9e05\">Тут</a> есть пример.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ВЫВОД 2.2**\n",
    "\n",
    "- использован TfidfVectorizer \n",
    "- наилучший результат показала LogisticRegression, на валидационной выборке F1 = 0.75, на тестовой 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ИТОГОВЫЙ ВЫВОД**\n",
    "\n",
    "- в тексте оставлены только слова, убраны стопслова, текст лемматизирован\n",
    "- текст в дальнейшем был преобразован в векторы двумя способами \n",
    "  1. BERT\n",
    "  2. TfidfVectorizer\n",
    "---\n",
    "  1. BERT\n",
    "- преобразование текста с помощью BERT трудоемкий процесс, занимает много памяти и времени для обработки (при использовании ноутбука для обработки всех строк потребовалось бы более 88 часов)\n",
    "- были использованы следующие модели: LogisticRegression, DecisionTreeClassifier, RandomForestClassifier, CatBoostClassifier\n",
    "- тем не менее с использованием BERT ( с учетом преобразования только 500 строк) логистическая регрессия показала f1 0.71, что скорее всего может быть улучшено с помощью gridsearchcv\n",
    "---\n",
    "  2. TfidfVectorizer\n",
    "- преобразование текста с помощью TfidfVectorizer дало более высокий результат по всем моделям\n",
    "- были ииспользованы следующие модели: LogisticRegression, DecisionTreeClassifier, RandomForestClassifier\n",
    "- логистическая регрессия показала на валидационной выборке F1 = 0.75, на тестовой 0.75"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-success\">\n",
    "<b>Успех:</b> Приятно видеть подробный вывод в конце проекта!\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**ВОПРОСЫ РЕВЬЮЕРУ**\n",
    "\n",
    "\n",
    "1. Можно ли как поместить предобработку текста в pipeline?\n",
    "2. Правильно ли был применен bert? можно ли как-то ускорить процесс? \n",
    "3. Зачем используется attention_mask?\n",
    "4. Где почитать поподробнее про torch? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<b>Ответы: </b> \n",
    "    \n",
    "1. Да, можно. Для этого нужно сделать свои классы с нужными методами: https://stackoverflow.com/questions/43232506/using-pipeline-with-custom-classes-in-sklearn , https://medium.com/analytics-vidhya/scikit-learn-pipelines-with-custom-transformer-a-step-by-step-guide-9b9b886fd2cc\n",
    "2. Да. Да. Подробнее в самом первом комментарии.\n",
    "3. Чтобы при кодировка текста не учитывать слова паддинги. БЕРТ принимает тексты длиной 512 токенов, поэтом используются паддинги\n",
    "4. Если что-то конкретное, то в документации, а так можешь поискать курсы/статьи в интернете."
   ]
  }
 ],
 "metadata": {
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
